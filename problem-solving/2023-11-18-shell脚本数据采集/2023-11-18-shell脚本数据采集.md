本来以为又是一次正常的 shell 脚本数据采集的过程

没想到这次居然问题频发



# 问题描述

## 采集方案

将所有机器中连续7天的日志，拉取到日志分析机中

再写一个 shell 脚本，来跑这些日志

同时将结果输出到一个统计文件中



## shell脚本

具体内容放在文末



### 数据样本迁移

由于这个服务部署在两套机器中（物理机和腾讯云），所以对于不同的部署方式，数据样本要用不同的方式来迁移

#### 物理机

使用 JumpServer 中的文件转移工具，来迁移打包好的日志压缩包到日志分析机中

#### 腾讯云

使用 k8s 工具 `dk8s` 来迁移打包好的日志压缩包到日志分析机中



## 遇到的问题

### 鉴权

使用 cookie，在后台系统中F12抓一个，然后直接放在脚本里，也可以给脚本传参，$2就可以指定鉴权 cookie，防止脚本中暂存的 cookie 过期

另外脚本中在执行之前，也有对 cookie 进行合法性校验的操作，如果调不通就会直接退出脚本

### 磁盘IO

服务器的磁盘IO，多次被拉满报警

![image](https://github.com/rabbeargiggly/tech-notes/blob/main/problem-solving/2023-11-18-shell%E8%84%9A%E6%9C%AC%E6%95%B0%E6%8D%AE%E9%87%87%E9%9B%86/resources/image.png)

刚开始OP同学来找我，我以为是拷贝的问题，因为我在 jumpserver 上提交了文件同步

![image](https://github.com/rabbeargiggly/tech-notes/blob/main/problem-solving/2023-11-18-shell%E8%84%9A%E6%9C%AC%E6%95%B0%E6%8D%AE%E9%87%87%E9%9B%86/resources/image2.png)



然后我就一个一个的同步，结果在我 tar 打包的时候，OP又来找我了，说又拉满了。。。。。

![image](https://github.com/rabbeargiggly/tech-notes/blob/main/problem-solving/2023-11-18-shell%E8%84%9A%E6%9C%AC%E6%95%B0%E6%8D%AE%E9%87%87%E9%9B%86/resources/image3.png)

好吧原来 tar 命令也会拉满磁盘IO，后面我就不 tar 了，我就把需要的日志都转移到一个目录下，然后让OP转移到分析机



结果在我转移的时候，又满了

因为我用的 find + cp 命令，find 命令也会拉满

![image](https://github.com/rabbeargiggly/tech-notes/blob/main/problem-solving/2023-11-18-shell%E8%84%9A%E6%9C%AC%E6%95%B0%E6%8D%AE%E9%87%87%E9%9B%86/resources/image4.png)









shell 脚本内容

```shell
#! /bin/bash
# $1 是日志存放路径，默认当前路径
# $2 是调用接口时 header 中附带的 cookie
# 运行日志在 pwd/double_login_filter_logs/ 中
# 运行结果在 pwd/double_login_filter_results/ 中

path=$PWD
cookie="******; auth_info=******; auth_hash=******; JSESSIONID=******"
url="https://******"
account_type_duoku=2

# =====================函数定义部分======================
# 主函数启动前，先校验 cookie 有效性，有效期6小时
check_cookie_expire(){
  http_result=$(curl -X POST -H "Content-Type: application/json" -H "Cookie:$cookie" -s $url)
 check_result=$(echo $http_result | grep "参数错误")
 if [[ "$check_result" == "" ]]
 then
 echo "cookie expired, please get a new cookie as the param2 from https://******" >> absolute_log_file_path
      echo "exit" >> $absolute_log_file_path
 exit 0
 fi
}

# 遍历目录及子目录，获取所有文件
get_file_and_process(){
  echo "$1 is a dir" >> $absolute_log_file_path
 for element in `ls $1`
 do
 dir_or_file=$1"/"$element
 element_name=`basename $dir_or_file`
 if [ -d $dir_or_file ]
      then
 # 过滤掉日志文件夹和结果文件夹
 if [[ "$element_name" != "double_login_filter_logs" && "$element_name" != "double_login_filter_results" ]]
 then
 get_file_and_process $dir_or_file # 继续遍历文件夹
 fi
 else
 if test $(basename "$0") = $element_name # 过滤掉这个脚本本身
 then
 continue
 fi
 process_file $dir_or_file
 fi
 done
}

# 逐行处理日志文件并获取 act2 的记录
process_file(){
  echo "process $1 start" >> $absolute_log_file_path
 echo "process $1 start"
 while read line # 逐行遍历文件$1
 do
 is_act2=$(echo $line | grep "\"action\":2,") # 是否包含 {"action":2,}
 if [[ "$is_act2" != "" ]]
 then
 process_act2 "$line" # 处理 action=2 的记录，加双引号当作整体传递，避免变量中的空格将其分割成多个参数
 fi
 done < $1
 echo "process $1 end ......" >> $absolute_log_file_path
 echo "process $1 end ......"
}

# 从 act2 的记录中截取 baiduId，并调接口查账号类型
process_act2(){
  # "BaiduOauthID":"*****","Baidu_AccessToken
 leftIndex="BaiduOauthID\":\""
 rightIndex="\",\"Baidu_AccessToken"

 content=$1
 is_baidu=$(echo $content | grep "BaiduOauthID\":")
 if [[ "$is_baidu" != "" ]]
 then
 temp=${content%$rightIndex*} # 截取 rightIndex 左边的部分
 baiduId=${temp#*$leftIndex} # 截取 leftIndex 右边的部分
 http_get_account_type $baiduId
 fi
}

# 调用接口根据 baiduId 查账号类型
http_get_account_type(){
  baiduId=$1
 echo "query account info:$baiduId" >> $absolute_log_file_path
 result=$(curl -X POST -H "Cookie:$cookie" -H "Content-Type:multipart/form-data" -F "baiduId=$baiduId" -s $url)

 echo "result:$result" >> $absolute_log_file_path
 errorCode=${result%%,*}
  errorCode=${errorCode#*"errorCode\" : "}
  if [ $errorCode -gt 0 ]
    then # 查询失败
 err_msg=${result%"\""*}
      err_msg=${err_msg##*"\""}
      # 为防止日志文件过大
 echo "query fail, baiduId:$baiduId, msg:$err_msg" >> $absolute_log_file_path
 else # 查询成功
 account_type=${result%"\\n\\t是否可用"*}
      account_type=${account_type#*"2-duoku) = "}  # 用户类型(0-baidu，1-91，2-duoku)
 echo "query success, baiduId=$baiduId, account type=$account_type" >> $absolute_log_file_path
 if [ $account_type -eq $account_type_duoku ]
        then
 if grep -q $baiduId $absolute_result_file_path # baiduId重复，-q查找时不输出内容，找到就返回0，否则返回1
 then
 echo "this baiduId is repeated, baiduId=$baiduId" >> $absolute_log_file_path
 else
 # 输出到结果文件中
 echo $baiduId >> $absolute_result_file_path
 fi
 fi
 fi
}
# ==================================================


current_timestamp=$(date +"%Y-%m-%d-%H:%M:%S")
# 创建运行日志
if [ ! -d "double_login_filter_logs" ]
  then
 mkdir "double_login_filter_logs"
fi
log_file_name="filter_log_"$current_timestamp
absolute_log_file_path="double_login_filter_logs"/$log_file_name
touch $absolute_log_file_path

# 创建结果日志
if [ ! -d "double_login_filter_results" ]
  then
 mkdir "double_login_filter_results"
fi
result_file_name="result_"$current_timestamp
absolute_result_file_path="double_login_filter_results"/$result_file_name
touch $absolute_result_file_path

if [ -z $2 ]; then
 echo "param 2 is empty, use default cookie" >> $absolute_log_file_path
else
 cookie=$2
fi
# 校验 cookie 有效性
#check_cookie_expire

if [ -z $1 ]; then
 echo "param 1 is empty, use default path" >> $absolute_log_file_path
else
 path=$1
fi
echo "path=$path, cookie=$cookie" >> $absolute_log_file_path

# 主程序启动
get_file_and_process $path
```

